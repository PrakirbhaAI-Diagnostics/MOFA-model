{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12f463dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "\n",
      "Filtering omics data based on pooled features...\n",
      "Dropping header row from CNV data.\n",
      "Data filtering complete.\n",
      "RNA filtered shape: (642, 458)\n",
      "MiRNA filtered shape: (631, 359)\n",
      "CNV filtered shape: (624, 481)\n",
      "Methylation filtered shape: (627, 478)\n",
      "Protein filtered shape: (624, 314)\n",
      "\n",
      "--- Processing Protein Data ---\n",
      "Merging Protein data...\n",
      "Merge complete. Shape: (624, 315)\n",
      "\n",
      "--- Processing Methylation Data ---\n",
      "Merging Methylation data...\n",
      "Merge complete. Shape: (627, 479)\n",
      "\n",
      "--- Processing MiRNA Data ---\n",
      "Merging MiRNA data...\n",
      "Merge complete. Shape: (631, 360)\n",
      "\n",
      "--- Processing CNV Data ---\n",
      "Merging CNV data...\n",
      "Merge complete. Shape: (624, 482)\n",
      "\n",
      "--- Processing RNA Data ---\n",
      "Merging RNA data...\n",
      "Merge complete. Shape: (631, 459)\n",
      "\n",
      "Found 624 common samples across all omics.\n",
      "\n",
      "Data split into 468 training samples and 156 testing samples.\n",
      "Binary Test set class distribution: binary_target\n",
      "0     49\n",
      "1    107\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training individual base models and collecting test probabilities...\n",
      "\n",
      "--- Training Protein Base Model ---\n",
      "Missing values handled for Protein using median imputation.\n",
      "  Applying BorderlineSMOTE for Protein...\n",
      "  Training ExtraTreesClassifier for Protein on resampled data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BITS\\.basilisk\\1.18.0\\0\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\BITS\\.basilisk\\1.18.0\\0\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "  File \"c:\\Users\\BITS\\.basilisk\\1.18.0\\0\\lib\\subprocess.py\", line 503, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"c:\\Users\\BITS\\.basilisk\\1.18.0\\0\\lib\\subprocess.py\", line 971, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\BITS\\.basilisk\\1.18.0\\0\\lib\\subprocess.py\", line 1456, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Getting test probabilities for ExtraTreesClassifier (Protein)...\n",
      "  Getting feature importance for ExtraTreesClassifier (Protein)...\n",
      "\n",
      "--- Training Methylation Base Model ---\n",
      "Missing values handled for Methylation using median imputation.\n",
      "  Applying ADASYN for Methylation...\n",
      "  Training RandomForestClassifier for Methylation on resampled data...\n",
      "  Getting test probabilities for RandomForestClassifier (Methylation)...\n",
      "  Getting feature importance for RandomForestClassifier (Methylation)...\n",
      "\n",
      "--- Training MiRNA Base Model ---\n",
      "Missing values handled for MiRNA using median imputation.\n",
      "  Applying ADASYN for MiRNA...\n",
      "  Training RandomForestClassifier for MiRNA on resampled data...\n",
      "  Getting test probabilities for RandomForestClassifier (MiRNA)...\n",
      "  Getting feature importance for RandomForestClassifier (MiRNA)...\n",
      "\n",
      "--- Training CNV Base Model ---\n",
      "Missing values handled for CNV using median imputation.\n",
      "  Training RandomForestClassifier for CNV with Class Weighting (Balanced)...\n",
      "  Getting test probabilities for RandomForestClassifier (CNV)...\n",
      "  Getting feature importance for RandomForestClassifier (CNV)...\n",
      "\n",
      "--- Training RNA Base Model ---\n",
      "Missing values handled for RNA using median imputation.\n",
      "  Applying BorderlineSMOTE for RNA...\n",
      "  Training RandomForestClassifier for RNA on resampled data...\n",
      "  Getting test probabilities for RandomForestClassifier (RNA)...\n",
      "  Getting feature importance for RandomForestClassifier (RNA)...\n",
      "\n",
      "--- Building and Evaluating Ensemble Model ---\n",
      "\n",
      "Evaluating Ensemble Model...\n",
      "\n",
      "--- Ensemble Evaluation Complete ---\n",
      "\n",
      "--- Ensemble Metrics ---\n",
      "                  Omics                   Model Technique Accuracy Balanced Accuracy Precision Recall (Sensitivity) Specificity F1-Score  G-Mean ROC-AUC  PR-AUC     MCC\n",
      "0  All Omics (Ensemble)  Ensemble (Soft Voting)  Combined   0.7115            0.5574    0.7123               0.9720      0.1429   0.8221  0.3726  0.5703  0.7415  0.2176\n",
      "\n",
      "--- Ensemble Confusion Matrix ---\n",
      "                      Predicted 0 (Not Early)  Predicted 1 (Early)\n",
      "Actual 0 (Not Early)                        7                   42\n",
      "Actual 1 (Early)                            3                  104\n",
      "\n",
      "--- Individual Base Model Feature Importances (Top 50) ---\n",
      "           Omics                   Model                   Technique                                    Feature  Importance\n",
      "0        Protein    ExtraTreesClassifier             BorderlineSMOTE  MAPK11/MAPK12/MAPK13/MAPK14_P38_pT180Y182    0.007274\n",
      "1        Protein    ExtraTreesClassifier             BorderlineSMOTE                             GSK3B_GSK3_pS9    0.006573\n",
      "2        Protein    ExtraTreesClassifier             BorderlineSMOTE                                  JAK2_JAK2    0.005508\n",
      "3        Protein    ExtraTreesClassifier             BorderlineSMOTE                         CTNNB1_BETACATENIN    0.005119\n",
      "4        Protein    ExtraTreesClassifier             BorderlineSMOTE                                  PCNA_PCNA    0.005024\n",
      "5        Protein    ExtraTreesClassifier             BorderlineSMOTE                        AKT1S1_PRAS40_pT246    0.005002\n",
      "6        Protein    ExtraTreesClassifier             BorderlineSMOTE                                   IDO1_IDO    0.004953\n",
      "7        Protein    ExtraTreesClassifier             BorderlineSMOTE                                EEF2K_EEF2K    0.004909\n",
      "8        Protein    ExtraTreesClassifier             BorderlineSMOTE                                  PAX8_PAX8    0.004840\n",
      "9        Protein    ExtraTreesClassifier             BorderlineSMOTE                             YAP1_YAP_pS127    0.004793\n",
      "10       Protein    ExtraTreesClassifier             BorderlineSMOTE                                GATA3_GATA3    0.004603\n",
      "11       Protein    ExtraTreesClassifier             BorderlineSMOTE                                   YBX1_YB1    0.004472\n",
      "12       Protein    ExtraTreesClassifier             BorderlineSMOTE                                 PTPRC_CD45    0.004470\n",
      "13       Protein    ExtraTreesClassifier             BorderlineSMOTE                              SERPINE1_PAI1    0.004450\n",
      "14       Protein    ExtraTreesClassifier             BorderlineSMOTE                                  TFRC_TFRC    0.004427\n",
      "15       Protein    ExtraTreesClassifier             BorderlineSMOTE                           PDPK1_PDK1_pS241    0.004399\n",
      "16       Protein    ExtraTreesClassifier             BorderlineSMOTE                                      AR_AR    0.004380\n",
      "17       Protein    ExtraTreesClassifier             BorderlineSMOTE                          PEA15_PEA15_pS116    0.004349\n",
      "18       Protein    ExtraTreesClassifier             BorderlineSMOTE                     EIF4EBP1_4EBP1_pT37T46    0.004319\n",
      "19       Protein    ExtraTreesClassifier             BorderlineSMOTE                              IGFBP2_IGFBP2    0.004318\n",
      "20       Protein    ExtraTreesClassifier             BorderlineSMOTE                                  ASNS_ASNS    0.004280\n",
      "21       Protein    ExtraTreesClassifier             BorderlineSMOTE                          STAT5A_STAT5ALPHA    0.004251\n",
      "22       Protein    ExtraTreesClassifier             BorderlineSMOTE                           SIRPA_SIRP-alpha    0.004248\n",
      "23       Protein    ExtraTreesClassifier             BorderlineSMOTE                                BAP1_BAP1C4    0.004244\n",
      "24       Protein    ExtraTreesClassifier             BorderlineSMOTE                                   DLAT_PDH    0.004242\n",
      "25       Protein    ExtraTreesClassifier             BorderlineSMOTE                          RPS6_S6_pS240S244    0.004223\n",
      "26       Protein    ExtraTreesClassifier             BorderlineSMOTE                                  MSH6_MSH6    0.004219\n",
      "27       Protein    ExtraTreesClassifier             BorderlineSMOTE                             CDH1_ECADHERIN    0.004209\n",
      "28       Protein    ExtraTreesClassifier             BorderlineSMOTE                            ULK1_ULK1_pS757    0.004188\n",
      "29       Protein    ExtraTreesClassifier             BorderlineSMOTE                       H3C1_Histone-H3_pS10    0.004170\n",
      "30       Protein    ExtraTreesClassifier             BorderlineSMOTE                             YWHAB_1433BETA    0.004162\n",
      "31       Protein    ExtraTreesClassifier             BorderlineSMOTE                              AKT1S1_PRAS40    0.004141\n",
      "32       Protein    ExtraTreesClassifier             BorderlineSMOTE                             CCNE2_CYCLINE2    0.004028\n",
      "33       Protein    ExtraTreesClassifier             BorderlineSMOTE                                ERCC5_ERCC5    0.004015\n",
      "34       Protein    ExtraTreesClassifier             BorderlineSMOTE                                  IRF1_IRF1    0.004005\n",
      "35       Protein    ExtraTreesClassifier             BorderlineSMOTE                                TRIM28_KAP1    0.004004\n",
      "36       Protein    ExtraTreesClassifier             BorderlineSMOTE                              INPP4B_INPP4B    0.003994\n",
      "37       Protein    ExtraTreesClassifier             BorderlineSMOTE                                CD276_B7-H3    0.003992\n",
      "38       Protein    ExtraTreesClassifier             BorderlineSMOTE                              PRKAR1A_PKA-a    0.003991\n",
      "39       Protein    ExtraTreesClassifier             BorderlineSMOTE                             CCNB1_CYCLINB1    0.003972\n",
      "40       Protein    ExtraTreesClassifier             BorderlineSMOTE                                CHD1L_CHD1L    0.003969\n",
      "41       Protein    ExtraTreesClassifier             BorderlineSMOTE                             YBX1_YB1_pS102    0.003945\n",
      "42       Protein    ExtraTreesClassifier             BorderlineSMOTE                                RAB25_RAB25    0.003936\n",
      "43       Protein    ExtraTreesClassifier             BorderlineSMOTE                              NOTCH3_Notch3    0.003927\n",
      "44       Protein    ExtraTreesClassifier             BorderlineSMOTE                           HSPB1_HSP27_pS82    0.003907\n",
      "45       Protein    ExtraTreesClassifier             BorderlineSMOTE                                  PARK7_DJ1    0.003903\n",
      "46       Protein    ExtraTreesClassifier             BorderlineSMOTE                             CLDN7_CLAUDIN7    0.003890\n",
      "47       Protein    ExtraTreesClassifier             BorderlineSMOTE                                MAP2K2_MEK2    0.003881\n",
      "48       Protein    ExtraTreesClassifier             BorderlineSMOTE                               ESR1_ERALPHA    0.003878\n",
      "49       Protein    ExtraTreesClassifier             BorderlineSMOTE                        SQSTM1_P62LCKLIGAND    0.003877\n",
      "50   Methylation  RandomForestClassifier                      ADASYN                                 cg02809591    0.008626\n",
      "51   Methylation  RandomForestClassifier                      ADASYN                                 cg23138608    0.006997\n",
      "52   Methylation  RandomForestClassifier                      ADASYN                                 cg25663764    0.006971\n",
      "53   Methylation  RandomForestClassifier                      ADASYN                                 cg02775417    0.006308\n",
      "54   Methylation  RandomForestClassifier                      ADASYN                                 cg16412460    0.005893\n",
      "55   Methylation  RandomForestClassifier                      ADASYN                                 cg05099145    0.005398\n",
      "56   Methylation  RandomForestClassifier                      ADASYN                                 cg19768607    0.005285\n",
      "57   Methylation  RandomForestClassifier                      ADASYN                                 cg05670953    0.005242\n",
      "58   Methylation  RandomForestClassifier                      ADASYN                                 cg09130077    0.005118\n",
      "59   Methylation  RandomForestClassifier                      ADASYN                                 cg08464505    0.005085\n",
      "60   Methylation  RandomForestClassifier                      ADASYN                                 cg04614173    0.004938\n",
      "61   Methylation  RandomForestClassifier                      ADASYN                                 cg05778494    0.004828\n",
      "62   Methylation  RandomForestClassifier                      ADASYN                                 cg03782130    0.004823\n",
      "63   Methylation  RandomForestClassifier                      ADASYN                                 cg05279413    0.004752\n",
      "64   Methylation  RandomForestClassifier                      ADASYN                                 cg04726821    0.004734\n",
      "65   Methylation  RandomForestClassifier                      ADASYN                                 cg11883836    0.004639\n",
      "66   Methylation  RandomForestClassifier                      ADASYN                                 cg03598185    0.004596\n",
      "67   Methylation  RandomForestClassifier                      ADASYN                                 cg23448584    0.004466\n",
      "68   Methylation  RandomForestClassifier                      ADASYN                                 cg16953816    0.004390\n",
      "69   Methylation  RandomForestClassifier                      ADASYN                                 cg15214183    0.004359\n",
      "70   Methylation  RandomForestClassifier                      ADASYN                                 cg18972013    0.004346\n",
      "71   Methylation  RandomForestClassifier                      ADASYN                                 cg00675569    0.004325\n",
      "72   Methylation  RandomForestClassifier                      ADASYN                                 cg08381325    0.004264\n",
      "73   Methylation  RandomForestClassifier                      ADASYN                                 cg09777525    0.004250\n",
      "74   Methylation  RandomForestClassifier                      ADASYN                                 cg12230250    0.004249\n",
      "75   Methylation  RandomForestClassifier                      ADASYN                                 cg24620761    0.004184\n",
      "76   Methylation  RandomForestClassifier                      ADASYN                                 cg19954537    0.004131\n",
      "77   Methylation  RandomForestClassifier                      ADASYN                                 cg24671344    0.004049\n",
      "78   Methylation  RandomForestClassifier                      ADASYN                                 cg03009158    0.004002\n",
      "79   Methylation  RandomForestClassifier                      ADASYN                                 cg03871675    0.003931\n",
      "80   Methylation  RandomForestClassifier                      ADASYN                                 cg04238303    0.003927\n",
      "81   Methylation  RandomForestClassifier                      ADASYN                                 cg11716106    0.003913\n",
      "82   Methylation  RandomForestClassifier                      ADASYN                                 cg05640754    0.003900\n",
      "83   Methylation  RandomForestClassifier                      ADASYN                                 cg21463554    0.003869\n",
      "84   Methylation  RandomForestClassifier                      ADASYN                                 cg15257681    0.003789\n",
      "85   Methylation  RandomForestClassifier                      ADASYN                                 cg00968561    0.003766\n",
      "86   Methylation  RandomForestClassifier                      ADASYN                                 cg15564619    0.003765\n",
      "87   Methylation  RandomForestClassifier                      ADASYN                                 cg15975865    0.003747\n",
      "88   Methylation  RandomForestClassifier                      ADASYN                                 cg15450349    0.003720\n",
      "89   Methylation  RandomForestClassifier                      ADASYN                                 cg24312105    0.003691\n",
      "90   Methylation  RandomForestClassifier                      ADASYN                                 cg00328720    0.003679\n",
      "91   Methylation  RandomForestClassifier                      ADASYN                                 cg12519998    0.003671\n",
      "92   Methylation  RandomForestClassifier                      ADASYN                                 cg02260430    0.003613\n",
      "93   Methylation  RandomForestClassifier                      ADASYN                                 cg21126344    0.003591\n",
      "94   Methylation  RandomForestClassifier                      ADASYN                                 cg25372165    0.003548\n",
      "95   Methylation  RandomForestClassifier                      ADASYN                                 cg19449286    0.003493\n",
      "96   Methylation  RandomForestClassifier                      ADASYN                                 cg22635676    0.003482\n",
      "97   Methylation  RandomForestClassifier                      ADASYN                                 cg02730714    0.003471\n",
      "98   Methylation  RandomForestClassifier                      ADASYN                                 cg18992570    0.003470\n",
      "99   Methylation  RandomForestClassifier                      ADASYN                                 cg15468129    0.003437\n",
      "100        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-30d-3p    0.009283\n",
      "101        MiRNA  RandomForestClassifier                      ADASYN                            hsa-miR-16-2-3p    0.009187\n",
      "102        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-18a-3p    0.008906\n",
      "103        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-223-5p    0.008689\n",
      "104        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-99a-3p    0.008175\n",
      "105        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-616-5p    0.007952\n",
      "106        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-197-3p    0.007431\n",
      "107        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-574-3p    0.006571\n",
      "108        MiRNA  RandomForestClassifier                      ADASYN                              hsa-miR-28-5p    0.006492\n",
      "109        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-539-5p    0.006090\n",
      "110        MiRNA  RandomForestClassifier                      ADASYN                            hsa-miR-133a-3p    0.005845\n",
      "111        MiRNA  RandomForestClassifier                      ADASYN                            hsa-miR-3200-3p    0.005821\n",
      "112        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-30a-3p    0.005733\n",
      "113        MiRNA  RandomForestClassifier                      ADASYN                            hsa-miR-374b-5p    0.005621\n",
      "114        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-483-5p    0.005559\n",
      "115        MiRNA  RandomForestClassifier                      ADASYN                            hsa-miR-664a-5p    0.005470\n",
      "116        MiRNA  RandomForestClassifier                      ADASYN                            hsa-miR-196a-5p    0.005469\n",
      "117        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-150-5p    0.005416\n",
      "118        MiRNA  RandomForestClassifier                      ADASYN                               hsa-miR-5694    0.005338\n",
      "119        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-224-5p    0.005317\n",
      "120        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-202-5p    0.005203\n",
      "121        MiRNA  RandomForestClassifier                      ADASYN                            hsa-miR-378a-5p    0.005175\n",
      "122        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-511-5p    0.005131\n",
      "123        MiRNA  RandomForestClassifier                      ADASYN                                hsa-miR-107    0.004882\n",
      "124        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-92b-3p    0.004861\n",
      "125        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-455-5p    0.004823\n",
      "126        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-361-5p    0.004735\n",
      "127        MiRNA  RandomForestClassifier                      ADASYN                           hsa-miR-29b-2-5p    0.004650\n",
      "128        MiRNA  RandomForestClassifier                      ADASYN                                hsa-miR-618    0.004645\n",
      "129        MiRNA  RandomForestClassifier                      ADASYN                            hsa-miR-4638-3p    0.004628\n",
      "130        MiRNA  RandomForestClassifier                      ADASYN                                hsa-miR-484    0.004602\n",
      "131        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-505-5p    0.004558\n",
      "132        MiRNA  RandomForestClassifier                      ADASYN                           hsa-miR-3150b-3p    0.004519\n",
      "133        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-34a-5p    0.004501\n",
      "134        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-218-5p    0.004441\n",
      "135        MiRNA  RandomForestClassifier                      ADASYN                            hsa-miR-193a-5p    0.004431\n",
      "136        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-145-5p    0.004345\n",
      "137        MiRNA  RandomForestClassifier                      ADASYN                                hsa-miR-944    0.004338\n",
      "138        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-889-3p    0.004288\n",
      "139        MiRNA  RandomForestClassifier                      ADASYN                            hsa-miR-196a-3p    0.004202\n",
      "140        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-99a-5p    0.004202\n",
      "141        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-101-3p    0.004166\n",
      "142        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-30b-3p    0.004094\n",
      "143        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-34c-3p    0.004088\n",
      "144        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-10b-5p    0.004032\n",
      "145        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-142-3p    0.004016\n",
      "146        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-141-3p    0.004000\n",
      "147        MiRNA  RandomForestClassifier                      ADASYN                            hsa-miR-190b-5p    0.003989\n",
      "148        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-154-5p    0.003980\n",
      "149        MiRNA  RandomForestClassifier                      ADASYN                             hsa-miR-27b-3p    0.003962\n",
      "150          CNV  RandomForestClassifier  Class Weighting (Balanced)                                     OR52K2    0.007749\n",
      "151          CNV  RandomForestClassifier  Class Weighting (Balanced)                                       PURA    0.006971\n",
      "152          CNV  RandomForestClassifier  Class Weighting (Balanced)                                   TARDBPP3    0.006945\n",
      "153          CNV  RandomForestClassifier  Class Weighting (Balanced)                                       MC4R    0.006317\n",
      "154          CNV  RandomForestClassifier  Class Weighting (Balanced)                                    MALINC1    0.006161\n",
      "155          CNV  RandomForestClassifier  Class Weighting (Balanced)                                       HES6    0.005937\n",
      "156          CNV  RandomForestClassifier  Class Weighting (Balanced)                                       CDNF    0.005928\n",
      "157          CNV  RandomForestClassifier  Class Weighting (Balanced)                                       IGIP    0.005633\n",
      "158          CNV  RandomForestClassifier  Class Weighting (Balanced)                                       SQLE    0.005355\n",
      "159          CNV  RandomForestClassifier  Class Weighting (Balanced)                                      SLEAR    0.004907\n",
      "160          CNV  RandomForestClassifier  Class Weighting (Balanced)                                     TPTEP1    0.004822\n",
      "161          CNV  RandomForestClassifier  Class Weighting (Balanced)                                    SUV39H2    0.004821\n",
      "162          CNV  RandomForestClassifier  Class Weighting (Balanced)                                      MEIG1    0.004816\n",
      "163          CNV  RandomForestClassifier  Class Weighting (Balanced)                                       VAPB    0.004741\n",
      "164          CNV  RandomForestClassifier  Class Weighting (Balanced)                                    HSFY1P1    0.004665\n",
      "165          CNV  RandomForestClassifier  Class Weighting (Balanced)                                     WASHC5    0.004654\n",
      "166          CNV  RandomForestClassifier  Class Weighting (Balanced)                                    FAM107B    0.004610\n",
      "167          CNV  RandomForestClassifier  Class Weighting (Balanced)                                    MIR1265    0.004493\n",
      "168          CNV  RandomForestClassifier  Class Weighting (Balanced)                                       SAT1    0.004475\n",
      "169          CNV  RandomForestClassifier  Class Weighting (Balanced)                                       XKR5    0.004468\n",
      "170          CNV  RandomForestClassifier  Class Weighting (Balanced)                                   PRELID3B    0.004441\n",
      "171          CNV  RandomForestClassifier  Class Weighting (Balanced)                                      TUBB1    0.004432\n",
      "172          CNV  RandomForestClassifier  Class Weighting (Balanced)                                     KLHL38    0.004429\n",
      "173          CNV  RandomForestClassifier  Class Weighting (Balanced)                                     RAB22A    0.004398\n",
      "174          CNV  RandomForestClassifier  Class Weighting (Balanced)                                    SPATA17    0.004386\n",
      "175          CNV  RandomForestClassifier  Class Weighting (Balanced)                                       OSR2    0.004384\n",
      "176          CNV  RandomForestClassifier  Class Weighting (Balanced)                                       IER5    0.004377\n",
      "177          CNV  RandomForestClassifier  Class Weighting (Balanced)                                      DEFA1    0.004351\n",
      "178          CNV  RandomForestClassifier  Class Weighting (Balanced)                                       LCAT    0.004230\n",
      "179          CNV  RandomForestClassifier  Class Weighting (Balanced)                                      CSDC2    0.004226\n",
      "180          CNV  RandomForestClassifier  Class Weighting (Balanced)                                      TRPS1    0.004226\n",
      "181          CNV  RandomForestClassifier  Class Weighting (Balanced)                                   MCPH1-DT    0.004202\n",
      "182          CNV  RandomForestClassifier  Class Weighting (Balanced)                                       XKR6    0.004201\n",
      "183          CNV  RandomForestClassifier  Class Weighting (Balanced)                                       XKR3    0.004108\n",
      "184          CNV  RandomForestClassifier  Class Weighting (Balanced)                                     PABPC1    0.004101\n",
      "185          CNV  RandomForestClassifier  Class Weighting (Balanced)                                      RPP38    0.004037\n",
      "186          CNV  RandomForestClassifier  Class Weighting (Balanced)                                      KRT34    0.004029\n",
      "187          CNV  RandomForestClassifier  Class Weighting (Balanced)                                      COX6C    0.004016\n",
      "188          CNV  RandomForestClassifier  Class Weighting (Balanced)                                      MED30    0.004001\n",
      "189          CNV  RandomForestClassifier  Class Weighting (Balanced)                                       GLUL    0.003979\n",
      "190          CNV  RandomForestClassifier  Class Weighting (Balanced)                                 APCDD1L-DT    0.003977\n",
      "191          CNV  RandomForestClassifier  Class Weighting (Balanced)                                    APCDD1L    0.003922\n",
      "192          CNV  RandomForestClassifier  Class Weighting (Balanced)                                       NMT2    0.003920\n",
      "193          CNV  RandomForestClassifier  Class Weighting (Balanced)                                      STX16    0.003882\n",
      "194          CNV  RandomForestClassifier  Class Weighting (Balanced)                                SLMO2-ATP5E    0.003874\n",
      "195          CNV  RandomForestClassifier  Class Weighting (Balanced)                                     MIR875    0.003869\n",
      "196          CNV  RandomForestClassifier  Class Weighting (Balanced)                                     TMEM65    0.003868\n",
      "197          CNV  RandomForestClassifier  Class Weighting (Balanced)                                     SLAMF7    0.003854\n",
      "198          CNV  RandomForestClassifier  Class Weighting (Balanced)                                    FAM91A1    0.003852\n",
      "199          CNV  RandomForestClassifier  Class Weighting (Balanced)                                      KRT37    0.003824\n",
      "200          RNA  RandomForestClassifier             BorderlineSMOTE                                  RN7SL711P    0.012798\n",
      "201          RNA  RandomForestClassifier             BorderlineSMOTE                                  RN7SL665P    0.009695\n",
      "202          RNA  RandomForestClassifier             BorderlineSMOTE                                       EPYC    0.009600\n",
      "203          RNA  RandomForestClassifier             BorderlineSMOTE                                      MEX3A    0.007102\n",
      "204          RNA  RandomForestClassifier             BorderlineSMOTE                                       IL20    0.006818\n",
      "205          RNA  RandomForestClassifier             BorderlineSMOTE                                     ZNF648    0.006729\n",
      "206          RNA  RandomForestClassifier             BorderlineSMOTE                                     VANGL2    0.006520\n",
      "207          RNA  RandomForestClassifier             BorderlineSMOTE                                     CAVIN2    0.006356\n",
      "208          RNA  RandomForestClassifier             BorderlineSMOTE                                     CLDN11    0.006172\n",
      "209          RNA  RandomForestClassifier             BorderlineSMOTE                                      CARMN    0.006013\n",
      "210          RNA  RandomForestClassifier             BorderlineSMOTE                                  RN7SKP255    0.005858\n",
      "211          RNA  RandomForestClassifier             BorderlineSMOTE                                      PSEN2    0.005747\n",
      "212          RNA  RandomForestClassifier             BorderlineSMOTE                                       DLX3    0.005581\n",
      "213          RNA  RandomForestClassifier             BorderlineSMOTE                                   ARHGAP40    0.005325\n",
      "214          RNA  RandomForestClassifier             BorderlineSMOTE                                     TUBA5P    0.005291\n",
      "215          RNA  RandomForestClassifier             BorderlineSMOTE                                      KIF12    0.005138\n",
      "216          RNA  RandomForestClassifier             BorderlineSMOTE                                  CDH13-AS2    0.005099\n",
      "217          RNA  RandomForestClassifier             BorderlineSMOTE                                    SNORD94    0.005087\n",
      "218          RNA  RandomForestClassifier             BorderlineSMOTE                                      ADCY5    0.004826\n",
      "219          RNA  RandomForestClassifier             BorderlineSMOTE                                   TMEM150C    0.004758\n",
      "220          RNA  RandomForestClassifier             BorderlineSMOTE                                   RNU1-67P    0.004710\n",
      "221          RNA  RandomForestClassifier             BorderlineSMOTE                                    CYP2T1P    0.004705\n",
      "222          RNA  RandomForestClassifier             BorderlineSMOTE                                     SLC7A3    0.004611\n",
      "223          RNA  RandomForestClassifier             BorderlineSMOTE                                    COL17A1    0.004564\n",
      "224          RNA  RandomForestClassifier             BorderlineSMOTE                                      TTC22    0.004543\n",
      "225          RNA  RandomForestClassifier             BorderlineSMOTE                                    CYP4Z2P    0.004477\n",
      "226          RNA  RandomForestClassifier             BorderlineSMOTE                                    SNORA7B    0.004404\n",
      "227          RNA  RandomForestClassifier             BorderlineSMOTE                                    CNTNAP2    0.004391\n",
      "228          RNA  RandomForestClassifier             BorderlineSMOTE                                      CAPN9    0.004351\n",
      "229          RNA  RandomForestClassifier             BorderlineSMOTE                                     CLDN19    0.004337\n",
      "230          RNA  RandomForestClassifier             BorderlineSMOTE                                     MAMDC2    0.004333\n",
      "231          RNA  RandomForestClassifier             BorderlineSMOTE                                  TNFRSF13C    0.004332\n",
      "232          RNA  RandomForestClassifier             BorderlineSMOTE                                     CLEC5A    0.004305\n",
      "233          RNA  RandomForestClassifier             BorderlineSMOTE                                  LINC02607    0.004075\n",
      "234          RNA  RandomForestClassifier             BorderlineSMOTE                                       PAK5    0.004060\n",
      "235          RNA  RandomForestClassifier             BorderlineSMOTE                                   ADAMTS16    0.004057\n",
      "236          RNA  RandomForestClassifier             BorderlineSMOTE                                      SCN2B    0.004050\n",
      "237          RNA  RandomForestClassifier             BorderlineSMOTE                                       CILP    0.004020\n",
      "238          RNA  RandomForestClassifier             BorderlineSMOTE                                  LINC02620    0.003962\n",
      "239          RNA  RandomForestClassifier             BorderlineSMOTE                                  RN7SL674P    0.003917\n",
      "240          RNA  RandomForestClassifier             BorderlineSMOTE                                      ABCA8    0.003901\n",
      "241          RNA  RandomForestClassifier             BorderlineSMOTE                                     DNAH14    0.003859\n",
      "242          RNA  RandomForestClassifier             BorderlineSMOTE                                    KRTCAP2    0.003643\n",
      "243          RNA  RandomForestClassifier             BorderlineSMOTE                                  RN7SL752P    0.003642\n",
      "244          RNA  RandomForestClassifier             BorderlineSMOTE                                      ASCL2    0.003620\n",
      "245          RNA  RandomForestClassifier             BorderlineSMOTE                                     HOTAIR    0.003560\n",
      "246          RNA  RandomForestClassifier             BorderlineSMOTE                                    TMPRSS3    0.003550\n",
      "247          RNA  RandomForestClassifier             BorderlineSMOTE                                      RCOR3    0.003550\n",
      "248          RNA  RandomForestClassifier             BorderlineSMOTE                                      MS4A1    0.003545\n",
      "249          RNA  RandomForestClassifier             BorderlineSMOTE                                      IGHA1    0.003542\n",
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "# from catboost import CatBoostClassifier # Uncomment if CatBoost is installed\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score,\n",
    "    matthews_corrcoef, precision_score, recall_score,\n",
    "    average_precision_score, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Import imblearn techniques\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.pipeline import Pipeline # Although we apply techniques manually here, Pipeline is useful\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='xgboost')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning) # imblearn might raise these\n",
    "\n",
    "# --- Data Loading and Filtering ---\n",
    "# Load all necessary data files\n",
    "try:\n",
    "    rna_data = pd.read_csv('D:\\\\extensive analysis data\\\\rna_samples_with_gene_names.csv')\n",
    "    mirna_data = pd.read_csv('D:\\\\extensive analysis data\\\\miRNA_samples.csv')\n",
    "    methylation_data = pd.read_csv(\"D:\\\\extensive analysis data\\\\methylation_samples.csv\")\n",
    "    cnv_data = pd.read_csv(\"D:\\\\extensive analysis data\\\\cnv_samples.csv\")\n",
    "    protein_data = pd.read_csv(\"D:\\\\extensive analysis data\\\\protein_samples.csv\")\n",
    "    clin_data = pd.read_csv('D:\\\\extensive analysis data\\\\clin_common.csv')\n",
    "    # Load the pooled data file containing the features to keep\n",
    "    pooled_data = pd.read_csv('D:\\\\Downloads\\\\Top Features - All Pooled.csv')\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading data file: {e}\")\n",
    "    print(\"Please check the file paths in the code.\")\n",
    "    sys.exit(1) # Exit the script if files are not found\n",
    "\n",
    "# Filter omics data based on features listed in pooled_data\n",
    "print(\"\\nFiltering omics data based on pooled features...\")\n",
    "\n",
    "# RNA filtering\n",
    "rna_features = pooled_data['Gene'].dropna().unique().tolist()\n",
    "# Ensure 'Unnamed: 0' (sample ID column) is always included\n",
    "rna_data_filtered = rna_data[['Unnamed: 0'] + [col for col in rna_features if col in rna_data.columns]].copy()\n",
    "\n",
    "# MiRNA filtering\n",
    "mirna_features = pooled_data['miRNA'].dropna().unique().tolist()\n",
    "mirna_data_filtered = mirna_data[['Unnamed: 0'] + [col for col in mirna_features if col in mirna_data.columns]].copy()\n",
    "\n",
    "# CNV filtering\n",
    "cnv_features = pooled_data['CNV'].dropna().unique().tolist()\n",
    "# CNV data had a header row that wasn't removed before, let's drop the first row if it exists and looks like a header\n",
    "if cnv_data.iloc[0].astype(str).str.contains('gene_id').any(): # Check if the first row contains 'gene_id'\n",
    "     print(\"Dropping header row from CNV data.\")\n",
    "     cnv_data = cnv_data.iloc[1:].copy()\n",
    "else:\n",
    "    cnv_data = cnv_data.copy() # Just copy if no header row detected\n",
    "\n",
    "# Convert columns to numeric after dropping header, coerce errors\n",
    "for col in cnv_data.columns:\n",
    "    if col != 'Unnamed: 0': # Avoid converting sample ID\n",
    "        cnv_data[col] = pd.to_numeric(cnv_data[col], errors='coerce')\n",
    "\n",
    "# Filter CNV data, exclude 'gene_id' if it exists as a column name in features\n",
    "cnv_data_filtered = cnv_data[['Unnamed: 0'] + [col for col in cnv_features if col in cnv_data.columns and col != 'gene_id']].copy()\n",
    "\n",
    "\n",
    "# Methylation filtering\n",
    "methylation_features = pooled_data['methylation'].dropna().unique().tolist()\n",
    "methylation_data_filtered = methylation_data[['Unnamed: 0'] + [col for col in methylation_features if col in methylation_data.columns]].copy()\n",
    "\n",
    "# Protein filtering\n",
    "protein_features = pooled_data['Protein'].dropna().unique().tolist()\n",
    "protein_data_filtered = protein_data[['Unnamed: 0'] + [col for col in protein_features if col in protein_data.columns]].copy()\n",
    "\n",
    "\n",
    "print(\"Data filtering complete.\")\n",
    "print(f\"RNA filtered shape: {rna_data_filtered.shape}\")\n",
    "print(f\"MiRNA filtered shape: {mirna_data_filtered.shape}\")\n",
    "print(f\"CNV filtered shape: {cnv_data_filtered.shape}\")\n",
    "print(f\"Methylation filtered shape: {methylation_data_filtered.shape}\")\n",
    "print(f\"Protein filtered shape: {protein_data_filtered.shape}\")\n",
    "\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def clean_sample_ids(sample_id_list):\n",
    "    \"\"\"Cleans sample IDs to a base format (e.g., TCGA-XX-XXXX-XX).\"\"\"\n",
    "    cleaned_ids = []\n",
    "    for sid in sample_id_list:\n",
    "        sid_str = str(sid)\n",
    "        # Use the pattern that matches the sample ID format\n",
    "        match = re.match(r'TCGA-\\w{2}-\\w{4}-\\w{2}', sid_str)\n",
    "        if match:\n",
    "            cleaned_ids.append(match.group(0))\n",
    "        else:\n",
    "            # If it doesn't match the standard pattern, keep the original or handle as error\n",
    "            # print(f\"Warning: Sample ID '{sid_str}' did not match expected pattern. Keeping original.\")\n",
    "            cleaned_ids.append(sid_str) # Keep original if no match\n",
    "    return cleaned_ids\n",
    "\n",
    "def merge_omics_clinical(omics_df, clinical_df, omics_name):\n",
    "    \"\"\"Merges omics and clinical data, handling sample ID cleaning.\"\"\"\n",
    "    print(f\"\\n--- Processing {omics_name} Data ---\")\n",
    "    print(f\"Merging {omics_name} data...\")\n",
    "    # Ensure 'Unnamed: 0' exists in omics_df and 'sample_id.1' in clinical_df\n",
    "    if 'Unnamed: 0' not in omics_df.columns:\n",
    "        print(f\"Error: '{omics_name}' dataframe is missing the 'Unnamed: 0' column for merging. Skipping.\")\n",
    "        return None\n",
    "    if 'sample_id.1' not in clinical_df.columns:\n",
    "        print(f\"Error: Clinical dataframe is missing the 'sample_id.1' column for merging. Skipping {omics_name}.\")\n",
    "        return None\n",
    "\n",
    "    # Clean omics sample IDs\n",
    "    omics_df['cleaned_sample_id'] = clean_sample_ids(omics_df['Unnamed: 0'])\n",
    "    # Clean clinical sample IDs (use 'sample_id.1' as it seems to be the correct identifier)\n",
    "    clinical_df['cleaned_sample_id'] = clean_sample_ids(clinical_df['sample_id.1'])\n",
    "\n",
    "    # Merge\n",
    "    # Use an inner merge to keep only samples present in both datasets\n",
    "    merged_df = pd.merge(omics_df, clinical_df[['cleaned_sample_id', 'stage_classification']],\n",
    "                         on='cleaned_sample_id', how='inner')\n",
    "\n",
    "    # Drop only the original omics ID column, keep 'cleaned_sample_id'\n",
    "    merged_df = merged_df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "    print(f\"Merge complete. Shape: {merged_df.shape}\")\n",
    "    return merged_df\n",
    "\n",
    "def handle_missing_values(df, strategy='median'):\n",
    "    \"\"\"Handles missing values using the specified strategy.\"\"\"\n",
    "    # print(f\"Handling missing values using strategy: {strategy}...\")\n",
    "    numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "    if strategy == 'median':\n",
    "        for col in numerical_cols:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    elif strategy == 'mean':\n",
    "        for col in numerical_cols:\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "    elif strategy == 'drop_rows':\n",
    "        df = df.dropna()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported imputation strategy\")\n",
    "\n",
    "    # print(f\"Missing value handling complete. Shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "# Use the evaluate_binary_model function provided by the user\n",
    "def evaluate_binary_model(y_true_binary, y_pred_binary, y_prob_binary=None, model_name=\"\", omics_name=\"\", technique_name=\"\"):\n",
    "    \"\"\"Evaluates a trained binary model and returns a dictionary of metrics.\"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics[\"Accuracy\"] = accuracy_score(y_true_binary, y_pred_binary)\n",
    "    metrics[\"Balanced Accuracy\"] = balanced_accuracy_score(y_true_binary, y_pred_binary)\n",
    "    metrics[\"MCC\"] = matthews_corrcoef(y_true_binary, y_pred_binary)\n",
    "\n",
    "    # Precision, Recall, F1 are for the positive class (1) in binary classification\n",
    "    # Ensure zero_division is handled to avoid warnings/errors on no positive predictions\n",
    "    precision = precision_score(y_true_binary, y_pred_binary, pos_label=1, zero_division=0)\n",
    "    recall = recall_score(y_true_binary, y_pred_binary, pos_label=1, zero_division=0) # Sensitivity\n",
    "    f1 = f1_score(y_true_binary, y_pred_binary, pos_label=1, zero_division=0)\n",
    "\n",
    "    metrics[\"Precision\"] = precision\n",
    "    metrics[\"Recall (Sensitivity)\"] = recall\n",
    "    metrics[\"F1-Score\"] = f1\n",
    "\n",
    "\n",
    "    # Specificity (Recall of the negative class)\n",
    "    unique_test_binary_classes = np.unique(y_true_binary)\n",
    "    if len(unique_test_binary_classes) < 2:\n",
    "        specificity = np.nan # Cannot calculate specificity if only one class in test set\n",
    "    else:\n",
    "        cm = confusion_matrix(y_true_binary, y_pred_binary)\n",
    "        # Ensure cm has the expected shape (2x2) even if predictions are all one class\n",
    "        if cm.shape == (2, 2):\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "        else:\n",
    "            # Handle cases where confusion_matrix might return a different shape\n",
    "            if 0 not in unique_test_binary_classes: # Only positive class (1) in test set\n",
    "                specificity = 0.0 # No true negatives possible\n",
    "            elif 1 not in unique_test_binary_classes: # Only negative class (0) in test set\n",
    "                specificity = 1.0 # All negatives correctly classified as negative\n",
    "            else:\n",
    "                # Fallback for unexpected shapes\n",
    "                print(f\"Warning: Unexpected confusion matrix shape {cm.shape} for evaluation ({omics_name} {model_name} {technique_name}). Specificity set to NaN.\")\n",
    "                specificity = np.nan\n",
    "\n",
    "    metrics[\"Specificity\"] = specificity\n",
    "\n",
    "    # G-Mean\n",
    "    if np.isnan(recall) or np.isnan(specificity):\n",
    "        metrics[\"G-Mean\"] = np.nan\n",
    "    else:\n",
    "        metrics[\"G-Mean\"] = np.sqrt(recall * specificity)\n",
    "\n",
    "\n",
    "    # AUC metrics require probability predictions\n",
    "    metrics[\"ROC-AUC\"] = np.nan\n",
    "    metrics[\"PR-AUC\"] = np.nan\n",
    "\n",
    "    if y_prob_binary is not None:\n",
    "        try:\n",
    "            if len(np.unique(y_true_binary)) > 1: # Need both classes in test set for AUC\n",
    "                 # Check if y_prob contains finite values before calculating AUC\n",
    "                if np.isfinite(y_prob_binary).all():\n",
    "                    metrics[\"ROC-AUC\"] = roc_auc_score(y_true_binary, y_prob_binary)\n",
    "                    metrics[\"PR-AUC\"] = average_precision_score(y_true_binary, y_prob_binary)\n",
    "                else:\n",
    "                     print(f\"Warning: Probability predictions contain non-finite values for evaluation ({omics_name} {model_name} {technique_name}). Cannot calculate AUC metrics.\")\n",
    "                     metrics[\"ROC-AUC\"] = np.nan\n",
    "                     metrics[\"PR-AUC\"] = np.nan\n",
    "            else:\n",
    "                # Warning already printed if test set has only one class\n",
    "                pass\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Error calculating AUC for evaluation ({omics_name} {model_name} {technique_name}): {e}\")\n",
    "            metrics[\"ROC-AUC\"] = np.nan\n",
    "            metrics[\"PR-AUC\"] = np.nan\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred during AUC calculation for evaluation ({omics_name} {model_name} {technique_name}): {e}\")\n",
    "            metrics[\"ROC-AUC\"] = np.nan\n",
    "            metrics[\"PR-AUC\"] = np.nan\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def get_feature_importance(model, feature_names, top_n=50):\n",
    "    \"\"\"Extracts and returns top N feature importances or coefficients.\"\"\"\n",
    "    importance_dict = {}\n",
    "    model_type = type(model).__name__\n",
    "\n",
    "    try:\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            # Tree-based models\n",
    "            importances = model.feature_importances_\n",
    "            sorted_indices = np.argsort(importances)[::-1]\n",
    "            top_features = [(feature_names[i], importances[i]) for i in sorted_indices[:top_n]]\n",
    "            importance_dict = dict(top_features)\n",
    "            # print(f\"Extracted top {top_n} feature importances for {model_type}.\")\n",
    "\n",
    "        elif hasattr(model, 'coef_'):\n",
    "            # Linear models (Logistic Regression, SVC with linear kernel)\n",
    "            # For binary classification, coef_ is shape (1, n_features) or (n_features,)\n",
    "            # For multi-class (OvR or OvO), it's shape (n_classes, n_features)\n",
    "            # We are doing binary 'Early vs Not Early', so expect (1, n_features) or (n_features,)\n",
    "            if model.coef_.ndim > 1:\n",
    "                 # If it's multi-class coef (from OvR or OvO), take the coefficients for the positive class (index 1)\n",
    "                # This might need adjustment based on how the model handles binary internally, but for LR it's usually 1 row.\n",
    "                # Let's assume it's a single row for the binary case or take the first row if it's (1, n_features)\n",
    "                 coefs = model.coef_[0] if model.coef_.shape[0] == 1 else model.coef_[0] # Take the first row if shape is (1, n_features)\n",
    "                 if model.coef_.shape[0] > 1:\n",
    "                      print(f\"Warning: Model {model_type} has multi-dimensional coef_ ({model.coef_.shape}). Taking the first row for feature importance.\")\n",
    "            else:\n",
    "                coefs = model.coef_ # Shape (n_features,)\n",
    "\n",
    "            # Use absolute values for importance for ranking, but store original coefficient\n",
    "            abs_coefs = np.abs(coefs)\n",
    "            sorted_indices = np.argsort(abs_coefs)[::-1]\n",
    "            top_features = [(feature_names[i], coefs[i]) for i in sorted_indices[:top_n]] # Store original coefficient\n",
    "            importance_dict = dict(top_features)\n",
    "            # print(f\"Extracted top {top_n} coefficients (as importance) for {model_type}.\")\n",
    "\n",
    "        else:\n",
    "            # Models that don't support direct feature importance/coefficients\n",
    "            # print(f\"Model {model_type} does not support direct feature importance extraction.\")\n",
    "            pass # Return empty dictionary\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting feature importance for {model_type}: {e}\")\n",
    "        importance_dict = {} # Return empty dictionary on error\n",
    "\n",
    "    return importance_dict\n",
    "\n",
    "\n",
    "# --- Ensemble Configuration ---\n",
    "ensemble_config = {\n",
    "    \"Protein\": {\"model\": ExtraTreesClassifier(random_state=42), \"technique\": BorderlineSMOTE(random_state=42), \"omics_df\": protein_data_filtered},\n",
    "    \"Methylation\": {\"model\": RandomForestClassifier(random_state=42), \"technique\": ADASYN(random_state=42), \"omics_df\": methylation_data_filtered},\n",
    "    \"MiRNA\": {\"model\": RandomForestClassifier(random_state=42), \"technique\": ADASYN(random_state=42), \"omics_df\": mirna_data_filtered},\n",
    "    \"CNV\": {\"model\": RandomForestClassifier(random_state=42), \"technique\": \"Class Weighting (Balanced)\", \"omics_df\": cnv_data_filtered},\n",
    "    \"RNA\": {\"model\": RandomForestClassifier(random_state=42), \"technique\": BorderlineSMOTE(random_state=42), \"omics_df\": rna_data_filtered},\n",
    "}\n",
    "\n",
    "# --- Main Ensemble Building and Evaluation Logic ---\n",
    "\n",
    "trained_base_models = {}\n",
    "all_feature_importances = []\n",
    "test_probabilities = {} # To store probabilities for soft voting\n",
    "\n",
    "# First, merge clinical data with each omics dataset and get the binary target\n",
    "merged_omics_data = {}\n",
    "for omics_name, config in ensemble_config.items():\n",
    "     omics_df = config[\"omics_df\"].copy()\n",
    "     merged_df = merge_omics_clinical(omics_df, clin_data.copy(), omics_name)\n",
    "     if merged_df is not None:\n",
    "          merged_df['binary_target'] = (merged_df['stage_classification'] == 'Early Stage').astype(int)\n",
    "          merged_omics_data[omics_name] = merged_df\n",
    "     else:\n",
    "          print(f\"Skipping {omics_name} for ensemble due to merge failure.\")\n",
    "\n",
    "\n",
    "# Check if we have any data to proceed\n",
    "if not merged_omics_data:\n",
    "    print(\"No omics data successfully merged. Cannot build ensemble. Exiting.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Get a common set of sample IDs present in all merged datasets\n",
    "common_sample_ids = None\n",
    "for omics_name, merged_df in merged_omics_data.items():\n",
    "    # Ensure the index is reset or use a unique ID column if available after merge\n",
    "    # We modified merge_omics_clinical to keep 'cleaned_sample_id'\n",
    "    if 'cleaned_sample_id' in merged_df.columns:\n",
    "        merged_df_indexed = merged_df.set_index('cleaned_sample_id')\n",
    "    else:\n",
    "        print(f\"Error: 'cleaned_sample_id' not found in {omics_name} merged data. Cannot proceed with consistent sample splitting. Exiting.\")\n",
    "        sys.exit()\n",
    "\n",
    "    current_ids = merged_df_indexed.index.tolist()\n",
    "    if common_sample_ids is None:\n",
    "        common_sample_ids = set(current_ids)\n",
    "    else:\n",
    "        common_sample_ids.intersection_update(current_ids)\n",
    "\n",
    "    # Update the entry in merged_omics_data with the indexed dataframe for consistent access\n",
    "    merged_omics_data[omics_name] = merged_df_indexed\n",
    "\n",
    "\n",
    "common_sample_ids = list(common_sample_ids)\n",
    "\n",
    "if not common_sample_ids:\n",
    "     print(\"No common samples found across all merged omics datasets. Cannot build ensemble. Exiting.\")\n",
    "     sys.exit()\n",
    "\n",
    "print(f\"\\nFound {len(common_sample_ids)} common samples across all omics.\")\n",
    "\n",
    "# Use the common sample IDs to create a consistent split across all omics\n",
    "# We'll split the indices/sample IDs first\n",
    "train_indices, test_indices = train_test_split(\n",
    "    common_sample_ids,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    # Stratify based on the binary target from one of the omics (assuming target distribution is similar)\n",
    "    # Use the target from the first successfully merged and indexed omics\n",
    "    stratify=merged_omics_data[list(merged_omics_data.keys())[0]].loc[common_sample_ids, 'binary_target']\n",
    ")\n",
    "\n",
    "print(f\"\\nData split into {len(train_indices)} training samples and {len(test_indices)} testing samples.\")\n",
    "\n",
    "# Store the true binary target for the test set (consistent across all omics)\n",
    "y_test_binary = merged_omics_data[list(merged_omics_data.keys())[0]].loc[test_indices, 'binary_target']\n",
    "print(\"Binary Test set class distribution:\", pd.Series(y_test_binary).value_counts().sort_index())\n",
    "\n",
    "if len(np.unique(y_test_binary)) < 2:\n",
    "    print(\"Warning: Binary test set contains fewer than 2 classes. AUC metrics for ensemble will be NaN.\")\n",
    "\n",
    "\n",
    "print(\"\\nTraining individual base models and collecting test probabilities...\")\n",
    "\n",
    "# Train each base model and collect test probabilities\n",
    "for omics_name, config in ensemble_config.items():\n",
    "    print(f\"\\n--- Training {omics_name} Base Model ---\")\n",
    "    merged_df_indexed = merged_omics_data.get(omics_name) # Get the pre-merged and indexed dataframe\n",
    "\n",
    "    if merged_df_indexed is None:\n",
    "        print(f\"Skipping {omics_name} as merged data was not available.\")\n",
    "        continue\n",
    "\n",
    "    # Select data for the current omics using the common train/test indices\n",
    "    X_omics = merged_df_indexed.drop(['stage_classification', 'binary_target'], axis=1)\n",
    "    y_omics_binary = merged_df_indexed['binary_target'] # Should be same as y_binary from the first omics\n",
    "\n",
    "    X_train_omics = X_omics.loc[train_indices].copy()\n",
    "    X_test_omics = X_omics.loc[test_indices].copy()\n",
    "    y_train_omics_binary = y_omics_binary.loc[train_indices].copy() # Use omics-specific target for training\n",
    "\n",
    "    # Handle Missing Values (Fit on training data for this omics)\n",
    "    X_train_omics = handle_missing_values(X_train_omics, strategy='median')\n",
    "    X_test_omics = handle_missing_values(X_test_omics, strategy='median')\n",
    "    print(f\"Missing values handled for {omics_name} using median imputation.\")\n",
    "\n",
    "    # Preprocess Features (Scaling - Fit on training data for this omics)\n",
    "    scaler_omics = StandardScaler()\n",
    "    X_train_omics_scaled = scaler_omics.fit_transform(X_train_omics)\n",
    "    X_test_omics_scaled = scaler_omics.transform(X_test_omics)\n",
    "    feature_names_omics = X_train_omics.columns.tolist() # Get feature names for this omics\n",
    "\n",
    "    # Get model and technique from config\n",
    "    model_instance_original = config[\"model\"]\n",
    "    technique = config[\"technique\"]\n",
    "    model_name = type(model_instance_original).__name__\n",
    "    technique_name = technique if isinstance(technique, str) else type(technique).__name__\n",
    "\n",
    "    current_model = None\n",
    "    X_train_res = X_train_omics_scaled.copy()\n",
    "    y_train_res = y_train_omics_binary.copy()\n",
    "\n",
    "    try:\n",
    "        # --- Apply Technique ---\n",
    "        if technique_name == \"None\":\n",
    "            # No sampling, use base model with default/scale_pos_weight\n",
    "            current_model = model_instance_original.__class__(**model_instance_original.get_params())\n",
    "            # Apply scale_pos_weight for XGBoost/LightGBM if no sampling\n",
    "            train_binary_counts_omics = pd.Series(y_train_omics_binary).value_counts().sort_index()\n",
    "            scale_pos_weight_value_omics = 1.0\n",
    "            if 0 in train_binary_counts_omics.index and 1 in train_binary_counts_omics.index and train_binary_counts_omics[1] != 0:\n",
    "                scale_pos_weight_value_omics = train_binary_counts_omics[0] / train_binary_counts_omics[1]\n",
    "                print(f\"  Calculated scale_pos_weight for {omics_name}: {scale_pos_weight_value_omics:.4f}\")\n",
    "            else:\n",
    "                 print(f\"  Warning: Could not calculate scale_pos_weight for {omics_name} (minority class count is zero). Setting to 1.0.\")\n",
    "\n",
    "            if model_name in [\"XGBClassifier\", \"LGBMClassifier\"]:\n",
    "                 current_model.set_params(scale_pos_weight=scale_pos_weight_value_omics)\n",
    "            # Ensure class_weight is not set if it's not the dedicated technique\n",
    "            if model_name in [\"LogisticRegression\", \"DecisionTreeClassifier\", \"SVC\", \"RandomForestClassifier\", \"ExtraTreesClassifier\"] and 'class_weight' in current_model.get_params():\n",
    "                 current_model.set_params(class_weight=None)\n",
    "\n",
    "\n",
    "            print(f\"  Training {model_name} for {omics_name} with None (no sampling)...\")\n",
    "            current_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "        elif technique_name == \"Class Weighting (Balanced)\":\n",
    "            # Apply class_weight='balanced' for models that support it\n",
    "            if model_name in [\"LogisticRegression\", \"DecisionTreeClassifier\", \"SVC\", \"RandomForestClassifier\", \"ExtraTreesClassifier\"]:\n",
    "                current_model = model_instance_original.__class__(**model_instance_original.get_params())\n",
    "                current_model.set_params(class_weight='balanced')\n",
    "                print(f\"  Training {model_name} for {omics_name} with Class Weighting (Balanced)...\")\n",
    "                current_model.fit(X_train_res, y_train_res)\n",
    "            else:\n",
    "                print(f\"  Skipping Class Weighting for {model_name} ({omics_name}) as it's not directly supported via class_weight='balanced'.\")\n",
    "                continue # Skip this omics/model combination if class weighting is requested but not supported\n",
    "\n",
    "        else:\n",
    "            # Apply sampling techniques from imblearn\n",
    "            sampler = technique # technique is already the sampler instance\n",
    "\n",
    "            # Check if sampling is possible (requires min samples for some techniques)\n",
    "            min_samples_needed = 2 # Default for most samplers\n",
    "            if technique_name in [\"BorderlineSMOTE\", \"ADASYN\", \"SMOTETomek\", \"SMOTEENN\"]:\n",
    "                min_samples_needed = 6 # BorderlineSMOTE, ADASYN defaults k_neighbors=5, need k_neighbors+1 samples\n",
    "\n",
    "            train_binary_counts_omics = pd.Series(y_train_omics_binary).value_counts().sort_index()\n",
    "            if train_binary_counts_omics.min() < min_samples_needed and technique_name not in [\"RandomOverSampler\", \"RandomUnderSampler\"]:\n",
    "                print(f\"  Skipping {technique_name} for {omics_name} due to insufficient minority samples ({train_binary_counts_omics.min()}). Requires at least {min_samples_needed}.\")\n",
    "                continue # Skip this technique\n",
    "\n",
    "            if len(np.unique(y_train_omics_binary)) < 2:\n",
    "                print(f\"  Skipping {technique_name} for {omics_name} due to insufficient classes ({len(np.unique(y_train_omics_binary))}) in training data.\")\n",
    "                continue # Skip this technique\n",
    "\n",
    "\n",
    "            print(f\"  Applying {technique_name} for {omics_name}...\")\n",
    "            X_train_res, y_train_res = sampler.fit_resample(X_train_omics_scaled, y_train_omics_binary)\n",
    "\n",
    "            # Train the model on resampled data\n",
    "            current_model = model_instance_original.__class__(**model_instance_original.get_params())\n",
    "            # For XGBoost/LightGBM, set scale_pos_weight to 1.0 when sampling is used\n",
    "            if model_name in [\"XGBClassifier\", \"LGBMClassifier\"]:\n",
    "                 current_model.set_params(scale_pos_weight=1.0)\n",
    "            # Ensure class_weight is not set if sampling is used (except for NuSVC which is special)\n",
    "            if model_name in [\"LogisticRegression\", \"DecisionTreeClassifier\", \"SVC\", \"RandomForestClassifier\", \"ExtraTreesClassifier\"] and 'class_weight' in current_model.get_params():\n",
    "                 current_model.set_params(class_weight=None)\n",
    "\n",
    "\n",
    "            print(f\"  Training {model_name} for {omics_name} on resampled data...\")\n",
    "            current_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "        # --- Store Trained Model and Get Test Probabilities ---\n",
    "        if current_model is not None:\n",
    "            print(f\"  Getting test probabilities for {model_name} ({omics_name})...\")\n",
    "            # Ensure the model supports predict_proba\n",
    "            if hasattr(current_model, 'predict_proba'):\n",
    "                 try:\n",
    "                     # Get probability of the positive class (1)\n",
    "                     y_prob_test = current_model.predict_proba(X_test_omics_scaled)[:, 1]\n",
    "                     test_probabilities[omics_name] = y_prob_test\n",
    "                     trained_base_models[omics_name] = current_model # Store the trained model\n",
    "                 except Exception as e:\n",
    "                     print(f\"  Error getting predict_proba for {model_name} ({omics_name}): {e}. Skipping for ensemble.\")\n",
    "            else:\n",
    "                 print(f\"  Model {model_name} ({omics_name}) does not support predict_proba. Skipping for ensemble.\")\n",
    "\n",
    "\n",
    "            # --- Get Feature Importance for Base Model ---\n",
    "            print(f\"  Getting feature importance for {model_name} ({omics_name})...\")\n",
    "            feature_importance_data = get_feature_importance(current_model, feature_names_omics, top_n=50)\n",
    "\n",
    "            # Store feature importance\n",
    "            if feature_importance_data: # Only store if importance was extracted\n",
    "                for feature, importance in feature_importance_data.items():\n",
    "                    importance_entry = {\n",
    "                        'Omics': omics_name,\n",
    "                        'Model': model_name,\n",
    "                        'Technique': technique_name,\n",
    "                        'Feature': feature,\n",
    "                        'Importance': importance,\n",
    "                    }\n",
    "                    all_feature_importances.append(importance_entry)\n",
    "            else:\n",
    "                 # Store a placeholder if feature importance is not available\n",
    "                 importance_entry = {\n",
    "                        'Omics': omics_name,\n",
    "                        'Model': model_name,\n",
    "                        'Technique': technique_name,\n",
    "                        'Feature': 'N/A',\n",
    "                        'Importance': np.nan,\n",
    "                    }\n",
    "                 all_feature_importances.append(importance_entry)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {model_name} with {technique_name} for {omics_name}: {e}\")\n",
    "        # Note: We don't add metrics here, only for the final ensemble.\n",
    "        # We also don't add test probabilities for failed models.\n",
    "        # Add a placeholder for feature importance if an error occurred\n",
    "        importance_entry = {\n",
    "            'Omics': omics_name,\n",
    "            'Model': model_name,\n",
    "            'Technique': f\"{technique_name} (Failed)\",\n",
    "            'Feature': 'Error',\n",
    "            'Importance': np.nan,\n",
    "        }\n",
    "        all_feature_importances.append(importance_entry)\n",
    "\n",
    "\n",
    "# --- Ensemble Prediction and Evaluation ---\n",
    "print(\"\\n--- Building and Evaluating Ensemble Model ---\")\n",
    "\n",
    "# Check if we have trained models with probabilities to form an ensemble\n",
    "if not test_probabilities:\n",
    "    print(\"No base models successfully trained with probability prediction. Cannot build ensemble. Exiting.\")\n",
    "    # Print collected feature importances even if ensemble failed\n",
    "    if all_feature_importances:\n",
    "        summary_importance_df = pd.DataFrame(all_feature_importances)\n",
    "        print(\"\\nIndividual Base Model Feature Importances (Ensemble Failed):\")\n",
    "        print(summary_importance_df.to_string())\n",
    "    else:\n",
    "        print(\"\\nNo feature importances were collected.\")\n",
    "    sys.exit()\n",
    "\n",
    "# Combine probabilities from base models (Soft Voting)\n",
    "# Ensure all probability arrays have the same number of samples as the test set\n",
    "valid_probs = [probs for probs in test_probabilities.values() if len(probs) == len(y_test_binary)]\n",
    "\n",
    "if not valid_probs:\n",
    "    print(\"No valid test probabilities collected from base models. Cannot build ensemble. Exiting.\")\n",
    "    # Print collected feature importances even if ensemble failed\n",
    "    if all_feature_importances:\n",
    "        summary_importance_df = pd.DataFrame(all_feature_importances)\n",
    "        print(\"\\nIndividual Base Model Feature Importances (Ensemble Failed):\")\n",
    "        print(summary_importance_df.to_string())\n",
    "    else:\n",
    "        print(\"\\nNo feature importances were collected.\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "# Average the probabilities\n",
    "ensemble_probabilities = np.mean(valid_probs, axis=0)\n",
    "\n",
    "# Make final predictions (threshold at 0.5)\n",
    "ensemble_predictions = (ensemble_probabilities >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "print(\"\\nEvaluating Ensemble Model...\")\n",
    "ensemble_metrics = evaluate_binary_model(\n",
    "    y_test_binary,\n",
    "    ensemble_predictions,\n",
    "    y_prob_binary=ensemble_probabilities,\n",
    "    model_name=\"Ensemble (Soft Voting)\",\n",
    "    omics_name=\"All Omics\",\n",
    "    technique_name=\"Combined\"\n",
    ")\n",
    "\n",
    "# Store ensemble metrics\n",
    "all_metrics = [] # Reset metrics list to only store ensemble metrics\n",
    "metric_entry = {\n",
    "    'Omics': 'All Omics (Ensemble)',\n",
    "    'Model': 'Ensemble (Soft Voting)',\n",
    "    'Technique': 'Combined',\n",
    "}\n",
    "metric_entry.update(ensemble_metrics)\n",
    "all_metrics.append(metric_entry)\n",
    "\n",
    "\n",
    "print(\"\\n--- Ensemble Evaluation Complete ---\")\n",
    "\n",
    "# --- Print Summary Tables ---\n",
    "\n",
    "print(\"\\n--- Ensemble Metrics ---\")\n",
    "if all_metrics:\n",
    "    summary_metrics_df = pd.DataFrame(all_metrics)\n",
    "    # Reorder columns for better readability\n",
    "    metric_cols = [\"Accuracy\", \"Balanced Accuracy\", \"Precision\", \"Recall (Sensitivity)\",\n",
    "                   \"Specificity\", \"F1-Score\", \"G-Mean\", \"ROC-AUC\", \"PR-AUC\", \"MCC\"]\n",
    "    summary_cols = [\"Omics\", \"Model\", \"Technique\"] + metric_cols\n",
    "    summary_metrics_df = summary_metrics_df[summary_cols]\n",
    "\n",
    "    # Format numerical columns for display\n",
    "    for col in metric_cols:\n",
    "         if col in summary_metrics_df.columns:\n",
    "             summary_metrics_df[col] = summary_metrics_df[col].apply(lambda x: '{:.4f}'.format(x) if isinstance(x, (int, float)) and not np.isnan(x) else str(x))\n",
    "\n",
    "    # Print the metrics table\n",
    "    print(summary_metrics_df.to_string())\n",
    "else:\n",
    "    print(\"No ensemble metrics were generated.\")\n",
    "\n",
    "print(\"\\n--- Ensemble Confusion Matrix ---\")\n",
    "if len(np.unique(y_test_binary)) > 1:\n",
    "    cm = confusion_matrix(y_test_binary, ensemble_predictions)\n",
    "    cm_df = pd.DataFrame(cm, index=['Actual 0 (Not Early)', 'Actual 1 (Early)'], columns=['Predicted 0 (Not Early)', 'Predicted 1 (Early)'])\n",
    "    print(cm_df)\n",
    "else:\n",
    "    print(\"Cannot generate confusion matrix: Test set contains fewer than 2 classes.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Individual Base Model Feature Importances (Top 50) ---\")\n",
    "if all_feature_importances:\n",
    "    summary_importance_df = pd.DataFrame(all_feature_importances)\n",
    "    # Print the feature importance table\n",
    "    print(summary_importance_df.to_string())\n",
    "else:\n",
    "    print(\"No feature importances were extracted from base models.\")\n",
    "\n",
    "print(\"\\nScript finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c0f35ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4650786",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pooled_data.head()) # Display the first few rows of the pooled data for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec2a6aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "\n",
      "Filtering omics data based on pooled features...\n",
      "Data filtering complete.\n",
      "\n",
      "--- Analyzing Individual Feature Diagnostic Potential ---\n",
      "  Calculating ROC curves for all Protein features...\n",
      "  Saved combined ROC plot for Protein features.\n",
      "  Calculating ROC curves for all Methylation features...\n",
      "  Saved combined ROC plot for Methylation features.\n",
      "  Calculating ROC curves for all MiRNA features...\n",
      "  Saved combined ROC plot for MiRNA features.\n",
      "  Calculating ROC curves for all CNV features...\n",
      "  Saved combined ROC plot for CNV features.\n",
      "  Calculating ROC curves for all RNA features...\n",
      "  Saved combined ROC plot for RNA features.\n",
      "\n",
      "--- Top 20 Features by Individual Diagnostic Potential (AUC) ---\n",
      "          Omics          Feature       AUC   P-Value\n",
      "0   Methylation       cg03782130  0.603793  0.000030\n",
      "1   Methylation       cg10095954  0.602692  0.000037\n",
      "2   Methylation       cg25663764  0.602325  0.000039\n",
      "3   Methylation       cg00968561  0.599188  0.000067\n",
      "4           RNA             MMP9  0.598323  0.000076\n",
      "5         MiRNA   hsa-miR-455-3p  0.596388  0.000105\n",
      "6   Methylation       cg02809591  0.596157  0.000112\n",
      "7   Methylation       cg01503640  0.596086  0.000113\n",
      "8   Methylation       cg13089599  0.593956  0.000160\n",
      "9   Methylation       cg16438525  0.592973  0.000187\n",
      "10          RNA          TP53BP2  0.591895  0.000218\n",
      "11  Methylation       cg18397073  0.590274  0.000287\n",
      "12  Methylation       cg26501450  0.590227  0.000289\n",
      "13          RNA            TDRKH  0.589643  0.000310\n",
      "14  Methylation       cg19449286  0.588937  0.000353\n",
      "15  Methylation       cg22001208  0.588546  0.000374\n",
      "16        MiRNA  hsa-miR-1307-5p  0.588447  0.000373\n",
      "17  Methylation       cg02730714  0.587989  0.000408\n",
      "18  Methylation       cg06210783  0.587599  0.000432\n",
      "19  Methylation       cg01863319  0.587315  0.000451\n",
      "\n",
      "Full results saved to 'individual_feature_diagnostic_potential.csv'\n",
      "\n",
      "Found 624 common samples across all omics for model training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [624, 631]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 241\u001b[0m\n\u001b[0;32m    238\u001b[0m final_indexed_data \u001b[38;5;241m=\u001b[39m {name: df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_sample_id\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m name, df \u001b[38;5;129;01min\u001b[39;00m merged_omics_data\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# Split common sample IDs for training and testing\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m train_indices, test_indices \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommon_sample_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_indexed_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRNA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcommon_sample_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbinary_target\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m y_test_binary \u001b[38;5;241m=\u001b[39m final_indexed_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRNA\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[test_indices, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_target\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mData split into \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_indices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m training and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_indices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m testing samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\BITS\\.basilisk\\1.18.0\\0\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\BITS\\.basilisk\\1.18.0\\0\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2872\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2868\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2870\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2872\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2874\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[0;32m   2876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2877\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2878\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2879\u001b[0m     )\n\u001b[0;32m   2880\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\BITS\\.basilisk\\1.18.0\\0\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1908\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1878\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1879\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1880\u001b[0m \n\u001b[0;32m   1881\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1906\u001b[0m \u001b[38;5;124;03m    to an integer.\u001b[39;00m\n\u001b[0;32m   1907\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1908\u001b[0m     X, y, groups \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1909\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[0;32m   1910\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32mc:\\Users\\BITS\\.basilisk\\1.18.0\\0\\lib\\site-packages\\sklearn\\utils\\validation.py:532\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \n\u001b[0;32m    504\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    531\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 532\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\BITS\\.basilisk\\1.18.0\\0\\lib\\site-packages\\sklearn\\utils\\validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    478\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [624, 631]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score,\n",
    "    matthews_corrcoef, precision_score, recall_score,\n",
    "    average_precision_score, confusion_matrix, roc_curve, auc\n",
    ")\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ranksums\n",
    "\n",
    "# Import imblearn techniques\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='xgboost')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "# --- Data Loading and Filtering ---\n",
    "try:\n",
    "    rna_data = pd.read_csv('D:\\\\extensive analysis data\\\\rna_samples_with_gene_names.csv')\n",
    "    mirna_data = pd.read_csv('D:\\\\extensive analysis data\\\\miRNA_samples.csv')\n",
    "    methylation_data = pd.read_csv(\"D:\\\\extensive analysis data\\\\methylation_samples.csv\")\n",
    "    cnv_data = pd.read_csv(\"D:\\\\extensive analysis data\\\\cnv_samples.csv\")\n",
    "    protein_data = pd.read_csv(\"D:\\\\extensive analysis data\\\\protein_samples.csv\")\n",
    "    clin_data = pd.read_csv('D:\\\\extensive analysis data\\\\clin_common.csv')\n",
    "    pooled_data = pd.read_csv('D:\\\\Downloads\\\\Top Features - All Pooled.csv')\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading data file: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# --- Data Filtering ---\n",
    "print(\"\\nFiltering omics data based on pooled features...\")\n",
    "rna_features = pooled_data['Gene'].dropna().unique().tolist()\n",
    "rna_data_filtered = rna_data[['Unnamed: 0'] + [col for col in rna_features if col in rna_data.columns]].copy()\n",
    "\n",
    "mirna_features = pooled_data['miRNA'].dropna().unique().tolist()\n",
    "mirna_data_filtered = mirna_data[['Unnamed: 0'] + [col for col in mirna_features if col in mirna_data.columns]].copy()\n",
    "\n",
    "cnv_features = pooled_data['CNV'].dropna().unique().tolist()\n",
    "if 'gene_id' in cnv_data.iloc[0].astype(str).values:\n",
    "    cnv_data = cnv_data.iloc[1:].copy()\n",
    "for col in cnv_data.columns:\n",
    "    if col != 'Unnamed: 0':\n",
    "        cnv_data[col] = pd.to_numeric(cnv_data[col], errors='coerce')\n",
    "cnv_data_filtered = cnv_data[['Unnamed: 0'] + [col for col in cnv_features if col in cnv_data.columns]].copy()\n",
    "\n",
    "methylation_features = pooled_data['methylation'].dropna().unique().tolist()\n",
    "methylation_data_filtered = methylation_data[['Unnamed: 0'] + [col for col in methylation_features if col in methylation_data.columns]].copy()\n",
    "\n",
    "protein_features = pooled_data['Protein'].dropna().unique().tolist()\n",
    "protein_data_filtered = protein_data[['Unnamed: 0'] + [col for col in protein_features if col in protein_data.columns]].copy()\n",
    "\n",
    "print(\"Data filtering complete.\")\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def clean_sample_ids(sample_id_list):\n",
    "    cleaned_ids = []\n",
    "    for sid in sample_id_list:\n",
    "        sid_str = str(sid)\n",
    "        match = re.match(r'TCGA-\\w{2}-\\w{4}-\\w{2}', sid_str)\n",
    "        if match:\n",
    "            cleaned_ids.append(match.group(0))\n",
    "        else:\n",
    "            cleaned_ids.append(sid_str)\n",
    "    return cleaned_ids\n",
    "\n",
    "def merge_omics_clinical(omics_df, clinical_df, omics_name):\n",
    "    omics_df['cleaned_sample_id'] = clean_sample_ids(omics_df['Unnamed: 0'])\n",
    "    clinical_df['cleaned_sample_id'] = clean_sample_ids(clinical_df['sample_id.1'])\n",
    "    merged_df = pd.merge(omics_df, clinical_df[['cleaned_sample_id', 'stage_classification']],\n",
    "                         on='cleaned_sample_id', how='inner')\n",
    "    return merged_df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "def handle_missing_values(df, strategy='median'):\n",
    "    numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "    if strategy == 'median':\n",
    "        for col in numerical_cols:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    return df\n",
    "\n",
    "def evaluate_binary_model(y_true_binary, y_pred_binary, y_prob_binary=None):\n",
    "    metrics = {}\n",
    "    metrics[\"Accuracy\"] = accuracy_score(y_true_binary, y_pred_binary)\n",
    "    metrics[\"Balanced Accuracy\"] = balanced_accuracy_score(y_true_binary, y_pred_binary)\n",
    "    metrics[\"MCC\"] = matthews_corrcoef(y_true_binary, y_pred_binary)\n",
    "    metrics[\"Precision\"] = precision_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "    metrics[\"Recall (Sensitivity)\"] = recall_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "    metrics[\"F1-Score\"] = f1_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "    if len(np.unique(y_true_binary)) > 1:\n",
    "        cm = confusion_matrix(y_true_binary, y_pred_binary)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "        metrics[\"Specificity\"] = specificity\n",
    "        metrics[\"G-Mean\"] = np.sqrt(metrics[\"Recall (Sensitivity)\"] * specificity)\n",
    "        if y_prob_binary is not None:\n",
    "            metrics[\"ROC-AUC\"] = roc_auc_score(y_true_binary, y_prob_binary)\n",
    "            metrics[\"PR-AUC\"] = average_precision_score(y_true_binary, y_prob_binary)\n",
    "    return metrics\n",
    "\n",
    "def get_feature_importance(model, feature_names):\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        importances = np.abs(model.coef_[0])\n",
    "    else:\n",
    "        return {}\n",
    "    sorted_indices = np.argsort(importances)[::-1]\n",
    "    return {feature_names[i]: importances[i] for i in sorted_indices[:50]}\n",
    "    \n",
    "# =======================================================================\n",
    "# === START OF NEWLY ADDED SECTION FOR INDIVIDUAL FEATURE ANALYSIS ===\n",
    "# =======================================================================\n",
    "def analyze_individual_feature_potential(merged_data_dict):\n",
    "    \"\"\"\n",
    "    Calculates and plots the univariate ROC-AUC for every feature to find its\n",
    "    individual diagnostic potential.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Analyzing Individual Feature Diagnostic Potential ---\")\n",
    "    \n",
    "    univariate_results = []\n",
    "    output_dir = \"univariate_roc_plots\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for omics_name, merged_df in merged_data_dict.items():\n",
    "        print(f\"  Calculating ROC curves for all {omics_name} features...\")\n",
    "        \n",
    "        y_true = merged_df['binary_target']\n",
    "        X_features = merged_df.drop(columns=['cleaned_sample_id', 'stage_classification', 'binary_target'])\n",
    "\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        \n",
    "        for feature_name in X_features.columns:\n",
    "            feature_values = X_features[feature_name].dropna()\n",
    "            labels_for_feature = y_true[feature_values.index]\n",
    "\n",
    "            if len(labels_for_feature.unique()) < 2:\n",
    "                continue\n",
    "\n",
    "            fpr, tpr, _ = roc_curve(labels_for_feature, feature_values)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            \n",
    "            group_early = feature_values[labels_for_feature == 1]\n",
    "            group_not_early = feature_values[labels_for_feature == 0]\n",
    "            p_value = ranksums(group_early, group_not_early).pvalue if len(group_early) > 0 and len(group_not_early) > 0 else np.nan\n",
    "\n",
    "            univariate_results.append({\n",
    "                'Omics': omics_name,\n",
    "                'Feature': feature_name,\n",
    "                'AUC': roc_auc,\n",
    "                'P-Value': p_value\n",
    "            })\n",
    "\n",
    "            # Add this feature's curve to the combined plot\n",
    "            plt.plot(fpr, tpr, lw=1, alpha=0.7) # No label to avoid clutter\n",
    "        \n",
    "        # Finalize and save the combined plot for the current omics type\n",
    "        plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'Individual ROC Curves for All {omics_name} Features', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f\"{omics_name}_all_features_roc_curves.png\"))\n",
    "        plt.close() # Close the plot to free memory\n",
    "        print(f\"  Saved combined ROC plot for {omics_name} features.\")\n",
    "\n",
    "\n",
    "    # --- Create and Print Summary Table ---\n",
    "    if not univariate_results:\n",
    "        print(\"No features were analyzed. Cannot generate summary.\")\n",
    "        return\n",
    "\n",
    "    summary_df = pd.DataFrame(univariate_results).sort_values('AUC', ascending=False).reset_index(drop=True)\n",
    "    print(\"\\n--- Top 20 Features by Individual Diagnostic Potential (AUC) ---\")\n",
    "    print(summary_df.head(20).to_string())\n",
    "    summary_df.to_csv(\"individual_feature_diagnostic_potential.csv\", index=False)\n",
    "    print(\"\\nFull results saved to 'individual_feature_diagnostic_potential.csv'\")\n",
    "# =======================================================================\n",
    "# === END OF NEWLY ADDED SECTION ===\n",
    "# =======================================================================\n",
    "\n",
    "# --- Main Logic ---\n",
    "\n",
    "# Ensemble Configuration\n",
    "ensemble_config = {\n",
    "    \"Protein\": {\"model\": ExtraTreesClassifier(random_state=42), \"technique\": BorderlineSMOTE(random_state=42), \"omics_df\": protein_data_filtered},\n",
    "    \"Methylation\": {\"model\": RandomForestClassifier(random_state=42), \"technique\": ADASYN(random_state=42), \"omics_df\": methylation_data_filtered},\n",
    "    \"MiRNA\": {\"model\": RandomForestClassifier(random_state=42), \"technique\": ADASYN(random_state=42), \"omics_df\": mirna_data_filtered},\n",
    "    \"CNV\": {\"model\": RandomForestClassifier(random_state=42), \"technique\": \"Class Weighting (Balanced)\", \"omics_df\": cnv_data_filtered},\n",
    "    \"RNA\": {\"model\": RandomForestClassifier(random_state=42), \"technique\": BorderlineSMOTE(random_state=42), \"omics_df\": rna_data_filtered},\n",
    "}\n",
    "\n",
    "# Merge all omics data with clinical data\n",
    "merged_omics_data = {}\n",
    "for omics_name, config in ensemble_config.items():\n",
    "    merged_df = merge_omics_clinical(config[\"omics_df\"].copy(), clin_data.copy(), omics_name)\n",
    "    if merged_df is not None:\n",
    "        merged_df['binary_target'] = (merged_df['stage_classification'] == 'Early Stage').astype(int)\n",
    "        merged_omics_data[omics_name] = merged_df\n",
    "\n",
    "if not merged_omics_data:\n",
    "    sys.exit(\"No omics data successfully merged. Cannot proceed.\")\n",
    "\n",
    "# =======================================================================\n",
    "# ===> THE NEW FUNCTION IS CALLED HERE <===\n",
    "# =======================================================================\n",
    "analyze_individual_feature_potential(merged_omics_data)\n",
    "# =======================================================================\n",
    "\n",
    "# Find common samples for consistent train/test split\n",
    "common_sample_ids = set(merged_omics_data[list(merged_omics_data.keys())[0]]['cleaned_sample_id'])\n",
    "for omics_name in list(merged_omics_data.keys())[1:]:\n",
    "    common_sample_ids.intersection_update(merged_omics_data[omics_name]['cleaned_sample_id'])\n",
    "common_sample_ids = list(common_sample_ids)\n",
    "\n",
    "print(f\"\\nFound {len(common_sample_ids)} common samples across all omics for model training.\")\n",
    "\n",
    "# Create the final indexed data dictionary for the ensemble\n",
    "final_indexed_data = {name: df.set_index('cleaned_sample_id') for name, df in merged_omics_data.items()}\n",
    "\n",
    "# Split common sample IDs for training and testing\n",
    "train_indices, test_indices = train_test_split(\n",
    "    common_sample_ids,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=final_indexed_data['RNA'].loc[common_sample_ids, 'binary_target']\n",
    ")\n",
    "\n",
    "y_test_binary = final_indexed_data['RNA'].loc[test_indices, 'binary_target']\n",
    "print(f\"\\nData split into {len(train_indices)} training and {len(test_indices)} testing samples.\")\n",
    "\n",
    "# --- Train Base Models and Evaluate Ensemble ---\n",
    "trained_base_models = {}\n",
    "all_feature_importances = []\n",
    "test_probabilities = {}\n",
    "all_individual_metrics = []\n",
    "\n",
    "for omics_name, config in ensemble_config.items():\n",
    "    print(f\"\\n--- Processing {omics_name} Base Model ---\")\n",
    "    df_indexed = final_indexed_data[omics_name]\n",
    "    X = df_indexed.drop(['stage_classification', 'binary_target'], axis=1)\n",
    "    y = df_indexed['binary_target']\n",
    "\n",
    "    X_train, X_test = X.loc[train_indices], X.loc[test_indices]\n",
    "    y_train = y.loc[train_indices]\n",
    "\n",
    "    X_train = handle_missing_values(X_train, strategy='median')\n",
    "    X_test = handle_missing_values(X_test, strategy='median')\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    feature_names = X_train.columns.tolist()\n",
    "\n",
    "    model = config[\"model\"]\n",
    "    technique = config[\"technique\"]\n",
    "    model_name = type(model).__name__\n",
    "    technique_name = technique if isinstance(technique, str) else type(technique).__name__\n",
    "\n",
    "    try:\n",
    "        if technique_name == \"Class Weighting (Balanced)\":\n",
    "            model.set_params(class_weight='balanced')\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "        else:\n",
    "            X_res, y_res = technique.fit_resample(X_train_scaled, y_train)\n",
    "            model.fit(X_res, y_res)\n",
    "\n",
    "        # Evaluate and store individual model performance\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_prob = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        metrics = evaluate_binary_model(y_test_binary, y_pred, y_prob)\n",
    "        metric_entry = {'Omics': omics_name, 'Model': model_name, 'Technique': technique_name, **metrics}\n",
    "        all_individual_metrics.append(metric_entry)\n",
    "\n",
    "        if y_prob is not None:\n",
    "            test_probabilities[omics_name] = y_prob\n",
    "        \n",
    "        importances = get_feature_importance(model, feature_names)\n",
    "        for feature, importance in importances.items():\n",
    "            all_feature_importances.append({'Omics': omics_name, 'Feature': feature, 'Importance': importance})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error training {omics_name} model: {e}\")\n",
    "\n",
    "# --- Ensemble Evaluation ---\n",
    "if test_probabilities:\n",
    "    print(\"\\n--- Evaluating Ensemble Model ---\")\n",
    "    ensemble_probs = np.mean([p for p in test_probabilities.values()], axis=0)\n",
    "    ensemble_preds = (ensemble_probs >= 0.5).astype(int)\n",
    "    ensemble_metrics = evaluate_binary_model(y_test_binary, ensemble_preds, ensemble_probs)\n",
    "    \n",
    "    print(\"\\n--- Ensemble Metrics ---\")\n",
    "    print(pd.DataFrame([ensemble_metrics]).to_string())\n",
    "\n",
    "    print(\"\\n--- Ensemble Confusion Matrix ---\")\n",
    "    cm = confusion_matrix(y_test_binary, ensemble_preds)\n",
    "    print(pd.DataFrame(cm, index=['Actual Not Early', 'Actual Early'], columns=['Pred Not Early', 'Pred Early']))\n",
    "else:\n",
    "    print(\"\\nNo base models were successfully trained to form an ensemble.\")\n",
    "    \n",
    "# --- Final Summary Tables ---\n",
    "print(\"\\n--- Individual Omics Model Performance ---\")\n",
    "if all_individual_metrics:\n",
    "    print(pd.DataFrame(all_individual_metrics).to_string())\n",
    "\n",
    "print(\"\\n--- Top 50 Feature Importances from Base Models ---\")\n",
    "if all_feature_importances:\n",
    "    print(pd.DataFrame(all_feature_importances).sort_values('Importance', ascending=False).head(50).to_string())\n",
    "\n",
    "print(\"\\nScript finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f475ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score,\n",
    "    matthews_corrcoef, precision_score, recall_score,\n",
    "    average_precision_score, confusion_matrix, roc_curve, auc\n",
    ")\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ranksums\n",
    "\n",
    "# Import imblearn techniques\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='xgboost')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "# --- Data Loading and Filtering ---\n",
    "try:\n",
    "    rna_data = pd.read_csv('D:\\\\extensive analysis data\\\\rna_samples_with_gene_names.csv')\n",
    "    mirna_data = pd.read_csv('D:\\\\extensive analysis data\\\\miRNA_samples.csv')\n",
    "    methylation_data = pd.read_csv(\"D:\\\\extensive analysis data\\\\methylation_samples.csv\")\n",
    "    cnv_data = pd.read_csv(\"D:\\\\extensive analysis data\\\\cnv_samples.csv\")\n",
    "    protein_data = pd.read_csv(\"D:\\\\extensive analysis data\\\\protein_samples.csv\")\n",
    "    clin_data = pd.read_csv('D:\\\\extensive analysis data\\\\clin_common.csv')\n",
    "    pooled_data = pd.read_csv('D:\\\\Downloads\\\\Top Features - All Pooled.csv')\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading data file: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# --- Data Filtering ---\n",
    "print(\"\\nFiltering omics data based on pooled features...\")\n",
    "rna_features = pooled_data['Gene'].dropna().unique().tolist()\n",
    "rna_data_filtered = rna_data[['Unnamed: 0'] + [col for col in rna_features if col in rna_data.columns]].copy()\n",
    "\n",
    "mirna_features = pooled_data['miRNA'].dropna().unique().tolist()\n",
    "mirna_data_filtered = mirna_data[['Unnamed: 0'] + [col for col in mirna_features if col in mirna_data.columns]].copy()\n",
    "\n",
    "cnv_features = pooled_data['CNV'].dropna().unique().tolist()\n",
    "if 'gene_id' in cnv_data.iloc[0].astype(str).values:\n",
    "    cnv_data = cnv_data.iloc[1:].copy()\n",
    "for col in cnv_data.columns:\n",
    "    if col != 'Unnamed: 0':\n",
    "        cnv_data[col] = pd.to_numeric(cnv_data[col], errors='coerce')\n",
    "cnv_data_filtered = cnv_data[['Unnamed: 0'] + [col for col in cnv_features if col in cnv_data.columns]].copy()\n",
    "\n",
    "methylation_features = pooled_data['methylation'].dropna().unique().tolist()\n",
    "methylation_data_filtered = methylation_data[['Unnamed: 0'] + [col for col in methylation_features if col in methylation_data.columns]].copy()\n",
    "\n",
    "protein_features = pooled_data['Protein'].dropna().unique().tolist()\n",
    "protein_data_filtered = protein_data[['Unnamed: 0'] + [col for col in protein_features if col in protein_data.columns]].copy()\n",
    "\n",
    "print(\"Data filtering complete.\")\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def clean_sample_ids(sample_id_list):\n",
    "    cleaned_ids = []\n",
    "    for sid in sample_id_list:\n",
    "        sid_str = str(sid)\n",
    "        match = re.match(r'TCGA-\\w{2}-\\w{4}-\\w{2}', sid_str)\n",
    "        if match:\n",
    "            cleaned_ids.append(match.group(0))\n",
    "        else:\n",
    "            cleaned_ids.append(sid_str)\n",
    "    return cleaned_ids\n",
    "\n",
    "def merge_omics_clinical(omics_df, clinical_df, omics_name):\n",
    "    omics_df['cleaned_sample_id'] = clean_sample_ids(omics_df['Unnamed: 0'])\n",
    "    clinical_df['cleaned_sample_id'] = clean_sample_ids(clinical_df['sample_id.1'])\n",
    "    merged_df = pd.merge(omics_df, clinical_df[['cleaned_sample_id', 'stage_classification']],\n",
    "                         on='cleaned_sample_id', how='inner')\n",
    "    return merged_df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "def handle_missing_values(df, strategy='median'):\n",
    "    numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "    if strategy == 'median':\n",
    "        for col in numerical_cols:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    return df\n",
    "\n",
    "def evaluate_binary_model(y_true_binary, y_pred_binary, y_prob_binary=None):\n",
    "    metrics = {}\n",
    "    metrics[\"Accuracy\"] = accuracy_score(y_true_binary, y_pred_binary)\n",
    "    metrics[\"Balanced Accuracy\"] = balanced_accuracy_score(y_true_binary, y_pred_binary)\n",
    "    metrics[\"MCC\"] = matthews_corrcoef(y_true_binary, y_pred_binary)\n",
    "    metrics[\"Precision\"] = precision_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "    metrics[\"Recall (Sensitivity)\"] = recall_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "    metrics[\"F1-Score\"] = f1_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "    if len(np.unique(y_true_binary)) > 1:\n",
    "        cm = confusion_matrix(y_true_binary, y_pred_binary)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "        metrics[\"Specificity\"] = specificity\n",
    "        metrics[\"G-Mean\"] = np.sqrt(metrics[\"Recall (Sensitivity)\"] * specificity)\n",
    "        if y_prob_binary is not None:\n",
    "            metrics[\"ROC-AUC\"] = roc_auc_score(y_true_binary, y_prob_binary)\n",
    "            metrics[\"PR-AUC\"] = average_precision_score(y_true_binary, y_prob_binary)\n",
    "    return metrics\n",
    "\n",
    "def get_feature_importance(model, feature_names):\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        importances = np.abs(model.coef_[0])\n",
    "    else:\n",
    "        return {}\n",
    "    sorted_indices = np.argsort(importances)[::-1]\n",
    "    return {feature_names[i]: importances[i] for i in sorted_indices[:50]}\n",
    "    \n",
    "def analyze_individual_feature_potential(merged_data_dict):\n",
    "    print(\"\\n--- Analyzing Individual Feature Diagnostic Potential ---\")\n",
    "    univariate_results = []\n",
    "    output_dir = \"univariate_roc_plots\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for omics_name, merged_df in merged_data_dict.items():\n",
    "        print(f\"  Calculating ROC curves for all {omics_name} features...\")\n",
    "        y_true = merged_df['binary_target']\n",
    "        X_features = merged_df.drop(columns=['cleaned_sample_id', 'stage_classification', 'binary_target'])\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        for feature_name in X_features.columns:\n",
    "            feature_values = X_features[feature_name].dropna()\n",
    "            labels_for_feature = y_true[feature_values.index]\n",
    "            if len(labels_for_feature.unique()) < 2: continue\n",
    "            fpr, tpr, _ = roc_curve(labels_for_feature, feature_values)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            group_early = feature_values[labels_for_feature == 1]\n",
    "            group_not_early = feature_values[labels_for_feature == 0]\n",
    "            p_value = ranksums(group_early, group_not_early).pvalue if len(group_early) > 0 and len(group_not_early) > 0 else np.nan\n",
    "            univariate_results.append({'Omics': omics_name, 'Feature': feature_name, 'AUC': roc_auc, 'P-Value': p_value})\n",
    "            plt.plot(fpr, tpr, lw=1, alpha=0.7)\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--'); plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'Individual ROC Curves for All {omics_name} Features', fontsize=16)\n",
    "        plt.tight_layout(); plt.savefig(os.path.join(output_dir, f\"{omics_name}_all_features_roc_curves.png\")); plt.close()\n",
    "        print(f\"  Saved combined ROC plot for {omics_name} features.\")\n",
    "\n",
    "    if not univariate_results:\n",
    "        print(\"No features were analyzed. Cannot generate summary.\")\n",
    "        return\n",
    "    summary_df = pd.DataFrame(univariate_results).sort_values('AUC', ascending=False).reset_index(drop=True)\n",
    "    print(\"\\n--- Top 20 Features by Individual Diagnostic Potential (AUC) ---\")\n",
    "    print(summary_df.head(20).to_string())\n",
    "    summary_df.to_csv(\"individual_feature_diagnostic_potential.csv\", index=False)\n",
    "    print(\"\\nFull results saved to 'individual_feature_diagnostic_potential.csv'\")\n",
    "\n",
    "# --- Main Logic ---\n",
    "\n",
    "ensemble_config = {\n",
    "    \"Protein\": {\"model\": ExtraTreesClassifier(random_state=42), \"technique\": BorderlineSMOTE(random_state=42), \"omics_df\": protein_data_filtered},\n",
    "    \"Methylation\": {\"model\": RandomForestClassifier(random_state=42), \"technique\": ADASYN(random_state=42), \"omics_df\": methylation_data_filtered},\n",
    "    \"MiRNA\": {\"model\": RandomForestClassifier(random_state=42), \"technique\": ADASYN(random_state=42), \"omics_df\": mirna_data_filtered},\n",
    "    \"CNV\": {\"model\": RandomForestClassifier(random_state=42), \"technique\": \"Class Weighting (Balanced)\", \"omics_df\": cnv_data_filtered},\n",
    "    \"RNA\": {\"model\": RandomForestClassifier(random_state=42), \"technique\": BorderlineSMOTE(random_state=42), \"omics_df\": rna_data_filtered},\n",
    "}\n",
    "\n",
    "merged_omics_data = {}\n",
    "for omics_name, config in ensemble_config.items():\n",
    "    merged_df = merge_omics_clinical(config[\"omics_df\"].copy(), clin_data.copy(), omics_name)\n",
    "    if merged_df is not None:\n",
    "        merged_df['binary_target'] = (merged_df['stage_classification'] == 'Early Stage').astype(int)\n",
    "        merged_omics_data[omics_name] = merged_df\n",
    "\n",
    "if not merged_omics_data:\n",
    "    sys.exit(\"No omics data successfully merged. Cannot proceed.\")\n",
    "\n",
    "analyze_individual_feature_potential(merged_omics_data)\n",
    "\n",
    "# =======================================================================\n",
    "# === START OF FIX FOR ValueError ===\n",
    "# =======================================================================\n",
    "print(\"\\n--- Preparing data for ensemble model ---\")\n",
    "# De-duplicate each dataframe to ensure one entry per sample ID\n",
    "for omics_name, df in merged_omics_data.items():\n",
    "    if df['cleaned_sample_id'].duplicated().any():\n",
    "        print(f\"  Found and removed duplicate sample IDs in {omics_name} data.\")\n",
    "        merged_omics_data[omics_name] = df.drop_duplicates(subset='cleaned_sample_id', keep='first')\n",
    "\n",
    "# Now, create the indexed data dictionary\n",
    "final_indexed_data = {name: df.set_index('cleaned_sample_id') for name, df in merged_omics_data.items()}\n",
    "\n",
    "# Find common samples AFTER de-duplication\n",
    "common_sample_ids = set(final_indexed_data[list(final_indexed_data.keys())[0]].index)\n",
    "for omics_name in list(final_indexed_data.keys())[1:]:\n",
    "    common_sample_ids.intersection_update(final_indexed_data[omics_name].index)\n",
    "common_sample_ids = list(common_sample_ids)\n",
    "\n",
    "print(f\"Found {len(common_sample_ids)} common, unique samples across all omics for model training.\")\n",
    "# =======================================================================\n",
    "# === END OF FIX ===\n",
    "# =======================================================================\n",
    "\n",
    "# Split common sample IDs for training and testing\n",
    "train_indices, test_indices = train_test_split(\n",
    "    common_sample_ids,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=final_indexed_data['RNA'].loc[common_sample_ids, 'binary_target']\n",
    ")\n",
    "\n",
    "y_test_binary = final_indexed_data['RNA'].loc[test_indices, 'binary_target']\n",
    "print(f\"\\nData split into {len(train_indices)} training and {len(test_indices)} testing samples.\")\n",
    "\n",
    "# --- Train Base Models and Evaluate Ensemble ---\n",
    "# (The rest of the script remains the same)\n",
    "trained_base_models = {}\n",
    "all_feature_importances = []\n",
    "test_probabilities = {}\n",
    "all_individual_metrics = []\n",
    "\n",
    "for omics_name, config in ensemble_config.items():\n",
    "    print(f\"\\n--- Processing {omics_name} Base Model ---\")\n",
    "    df_indexed = final_indexed_data[omics_name]\n",
    "    \n",
    "    # Filter to only common samples before separating X and y\n",
    "    df_common = df_indexed.loc[common_sample_ids]\n",
    "    X = df_common.drop(['stage_classification', 'binary_target'], axis=1)\n",
    "    y = df_common['binary_target']\n",
    "\n",
    "    X_train, X_test = X.loc[train_indices], X.loc[test_indices]\n",
    "    y_train = y.loc[train_indices]\n",
    "\n",
    "    X_train = handle_missing_values(X_train, strategy='median')\n",
    "    X_test = handle_missing_values(X_test, strategy='median')\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    feature_names = X_train.columns.tolist()\n",
    "\n",
    "    model = config[\"model\"]\n",
    "    technique = config[\"technique\"]\n",
    "    model_name = type(model).__name__\n",
    "    technique_name = technique if isinstance(technique, str) else type(technique).__name__\n",
    "\n",
    "    try:\n",
    "        if technique_name == \"Class Weighting (Balanced)\":\n",
    "            model.set_params(class_weight='balanced')\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "        else:\n",
    "            X_res, y_res = technique.fit_resample(X_train_scaled, y_train)\n",
    "            model.fit(X_res, y_res)\n",
    "\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_prob = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        metrics = evaluate_binary_model(y_test_binary, y_pred, y_prob)\n",
    "        metric_entry = {'Omics': omics_name, 'Model': model_name, 'Technique': technique_name, **metrics}\n",
    "        all_individual_metrics.append(metric_entry)\n",
    "\n",
    "        if y_prob is not None:\n",
    "            test_probabilities[omics_name] = y_prob\n",
    "        \n",
    "        importances = get_feature_importance(model, feature_names)\n",
    "        for feature, importance in importances.items():\n",
    "            all_feature_importances.append({'Omics': omics_name, 'Feature': feature, 'Importance': importance})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error training {omics_name} model: {e}\")\n",
    "\n",
    "# --- Ensemble Evaluation ---\n",
    "if test_probabilities:\n",
    "    print(\"\\n--- Evaluating Ensemble Model ---\")\n",
    "    ensemble_probs = np.mean([p for p in test_probabilities.values()], axis=0)\n",
    "    ensemble_preds = (ensemble_probs >= 0.5).astype(int)\n",
    "    ensemble_metrics = evaluate_binary_model(y_test_binary, ensemble_preds, ensemble_probs)\n",
    "    \n",
    "    print(\"\\n--- Ensemble Metrics ---\")\n",
    "    print(pd.DataFrame([ensemble_metrics]).to_string())\n",
    "\n",
    "    print(\"\\n--- Ensemble Confusion Matrix ---\")\n",
    "    cm = confusion_matrix(y_test_binary, ensemble_preds)\n",
    "    print(pd.DataFrame(cm, index=['Actual Not Early', 'Actual Early'], columns=['Pred Not Early', 'Pred Early']))\n",
    "else:\n",
    "    print(\"\\nNo base models were successfully trained to form an ensemble.\")\n",
    "    \n",
    "# --- Final Summary Tables ---\n",
    "print(\"\\n--- Individual Omics Model Performance ---\")\n",
    "if all_individual_metrics:\n",
    "    print(pd.DataFrame(all_individual_metrics).to_string())\n",
    "\n",
    "print(\"\\n--- Top 50 Feature Importances from Base Models ---\")\n",
    "if all_feature_importances:\n",
    "    print(pd.DataFrame(all_feature_importances).sort_values('Importance', ascending=False).head(50).to_string())\n",
    "\n",
    "print(\"\\nScript finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
